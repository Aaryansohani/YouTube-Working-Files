{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "\n",
    "#H2O\n",
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "#Evaluation Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize H2O\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import train and test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = pd.concat([train, test], sort = False)\n",
    "all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Missing numbers with median for Age and Fare\n",
    "all['Age'] = all['Age'].fillna(value=all['Age'].median())\n",
    "all['Fare'] = all['Fare'].fillna(value=all['Fare'].median())\n",
    "\n",
    "#Treat Embarked\n",
    "all['Embarked'] = all['Embarked'].fillna(value=all['Embarked'].mode()[0])\n",
    "\n",
    "#Bin Age\n",
    "all.loc[ all['Age'] <= 16, 'Age'] = 0\n",
    "all.loc[(all['Age'] > 16) & (all['Age'] <= 32), 'Age'] = 1\n",
    "all.loc[(all['Age'] > 32) & (all['Age'] <= 48), 'Age'] = 2\n",
    "all.loc[(all['Age'] > 48) & (all['Age'] <= 64), 'Age'] = 3\n",
    "all.loc[ all['Age'] > 64, 'Age'] = 4 \n",
    "\n",
    "#Cabin\n",
    "all['Cabin'] = all['Cabin'].fillna('Missing')\n",
    "all['Cabin'] = all['Cabin'].str[0]\n",
    "\n",
    "#Family Size & Alone \n",
    "all['Family_Size'] = all['SibSp'] + all['Parch'] + 1\n",
    "all['IsAlone'] = 0\n",
    "all.loc[all['Family_Size']==1, 'IsAlone'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Features: Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract Title from Name\n",
    "all['Title'] = all['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will combine a few categories, since few of them are unique \n",
    "all['Title'] = all['Title'].replace(['Capt', 'Dr', 'Major', 'Rev'], 'Officer')\n",
    "all['Title'] = all['Title'].replace(['Lady', 'Countess', 'Don', 'Sir', 'Jonkheer', 'Dona'], 'Royal')\n",
    "all['Title'] = all['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "all['Title'] = all['Title'].replace(['Mme'], 'Mrs')\n",
    "all['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unwanted variables\n",
    "all = all.drop(['Name', 'Ticket'], axis = 1)\n",
    "all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy Values\n",
    "We will drop one of them using drop_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dummies = pd.get_dummies(all, drop_first = True)\n",
    "all_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covert Pandas Dataframe to H2O Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = h2o.H2OFrame(all_dummies[all_dummies['Survived'].notna()])\n",
    "all_test = h2o.H2OFrame(all_dummies[all_dummies['Survived'].isna()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get columns names for Building H2O Models\n",
    "target = 'Survived'\n",
    "predictors = [f for f in all_train.columns if f not in ['Survived','PassengerId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diving the dataset into Train, Validation and Test\n",
    "- **Train:** will be used to build model\n",
    "- **Validation** is used to help improve the evaluation metric (We will not use this in this kernel)\n",
    "- **Test** is used to help us evaluate the model we built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df, test_df = all_train.split_frame(ratios=[0.7, 0.15], seed=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert dtype to factor as per H2O implementation\n",
    "train_df[target] = train_df[target].asfactor()\n",
    "valid_df[target] = valid_df[target].asfactor()\n",
    "test_df[target] = test_df[target].asfactor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check X Variables\n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the H2O GBM \n",
    "gbm = H2OGradientBoostingEstimator()\n",
    "\n",
    "# train with the initialized model\n",
    "gbm.train(x=predictors, y=target, training_frame=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on Test Frame to evaluate how well our model performed\n",
    "#as_data_frame() converts the data to Pandas DataFrame\n",
    "pred_val = gbm.predict(test_df[predictors])[0].as_data_frame()\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_val = (test_df[target]).as_data_frame()\n",
    "prediction_auc = roc_auc_score(pred_val, true_val)\n",
    "prediction_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Predictions for Competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get X Variables from Competition Test Dataset\n",
    "TestForPred = all_test.drop(['PassengerId', 'Survived'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "fin_pred = gbm.predict(TestForPred[predictors])[0].as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Competition Test Ids\n",
    "PassengerId = all_test['PassengerId'].as_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Submission File\n",
    "h2o_Sub = pd.DataFrame({'PassengerId': PassengerId['PassengerId'].tolist(), 'Survived':fin_pred['predict'].tolist() })\n",
    "h2o_Sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Submission File\n",
    "h2o_Sub.to_csv(\"1_h2o_Submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
